import json
import numpy as np


def parse_lat(lat_in):
    """
    read lattice input file
    :param lat_in: file containing lattice information
    :return:
    """
    f = open(lat_in)
    lat = f.readlines()
    
    return 0


def parse_str(data_file):
    """
    Read in the DFT data and return to a list containing metadata dictionary for all DFT calculations
    :param data_file: file created by the vasp_compilation code from DFT data set
    :return: parsed DFT data list (str_list)
    """
    f = open(data_file)  # Read in DFT data
    data = f.readlines()
    f.close()
    str_dict = {}  # Dictionary containing all data and metadata for each DFT calculation
    str_list = []
    for i in range(len(data)):  # Begin parsing DFT data file
        if "#" in data[i]:  # "#" indicates a new DFT data point
            elem_name = data[i].split()  # List of the chemical species in the DFT data
            elem_name.pop(0)
            elem_num = len(elem_name)
            set_data = data[i + 1]
            set_data = set_data.split()
            name = set_data[elem_num]
            atom_numb = [int(set_data[i]) for i in range(elem_num)]
            atom_sum = sum(atom_numb)  # Total number of atoms in each DFT data point
            enrg = float(set_data[elem_num + 1]) / atom_sum
            lat_const = [float(set_data[elem_num + 2]), float(set_data[elem_num + 3]),
                         float(set_data[elem_num + 4])]
            lat_ang = [float(set_data[elem_num + 5]), float(set_data[elem_num + 6]),
                       float(set_data[elem_num + 7])]
            lat_vec = [data[i + 2 + j].split() for j in range(3)]
            lat_vec = [[float(lat_vec[j][k]) for k in range(len(lat_vec[j]))] for j in range(len(lat_vec))]
            vol = lat_const[0] * lat_const[1] * lat_const[2] * np.sqrt(1 - np.power(
                np.cos(lat_ang[0]), 2) - np.power(np.cos(lat_ang[1]), 2) - np.power(np.cos(lat_ang[2]), 2)
                    + 2 * np.cos(lat_ang[0]) * np.cos(lat_ang[1]) * np.cos(lat_ang[2])) / atom_sum
            lat_type = 'Direct'
            pos_list = []
            spin_list = []
            type_list = []
            spec_list = []
            for j in range(int(atom_sum)):
                line = data[i + j + 5]
                line = line.split()
                spin = float(line[2])
                atom_type = line[1]
                line = [float(line[k]) for k in range(3, 6)]
                atom_pos = line  # np.dot(np.transpose(line), lat_vec)
                pos_list.append(atom_pos)
                spin_list.append(spin)
                type_list.append(atom_type)
            for j in range(len(elem_name)):
                for k in range(int(atom_numb[j])):
                    spec_list.append(elem_name[j])
            str_dict['CellName'] = name  # structure names
            str_dict['LatVec'] = lat_vec  # lattice vectors in 3D
            str_dict['LatConst'] = lat_const  # lattice constants
            str_dict['UnitVol'] = vol  # volume per cell
            str_dict['Enrg'] = enrg  # energy per cell
            str_dict['ElemName'] = elem_name  # users-specified species names
            str_dict['ElemNum'] = elem_num  # number of users-specified species type
            str_dict['AtomNum'] = atom_numb  # number of each users-specified atomic species
            str_dict['AtomSum'] = atom_sum  # total number of atom
            str_dict['LatType'] = lat_type  # use direct coordinate
            str_dict['LatPnt'] = pos_list  # list of coordinates for each atom (existing in the str)
            str_dict['Spin'] = spin_list  # list of spin at each atom
            str_dict['Type'] = type_list  # list of species index of each atom
            str_dict['Spec'] = spec_list # list of species name of each atom
            str_list.append(str_dict.copy())
    return str_list


def find_avg_str(str_list):
    """
    merge redundant structure energies into an averaged energy in str_list
    :param str_list: list of structure metadata generated by parse_str function
    :return: avg_str_list
    """
    avg_str_list = []
    for str_dict in str_list:
        str_dict['Num_Redund'] = 1
        i = 0
        while i < len(avg_str_list):
            if str_dict['LatPnt'] == avg_str_list[i]['LatPnt'] \
                    and str_dict['Spin'] == avg_str_list[i]['Spin'] \
                    and str_dict['Type'] == avg_str_list[i]['Type'] \
                    and str_dict['LatVec'] == avg_str_list[i]['LatVec']:
                avg_str_list[i]['Enrg'] += str_dict['Enrg']
                avg_str_list[i]['Num_Redund'] += 1
                break
            else:
                i += 1
        if i >= len(avg_str_list):
            avg_str_list.append(str_dict)

    for str_dict in avg_str_list:
        str_dict['Enrg'] = str_dict['Enrg']/str_dict['Num_Redund']

    return avg_str_list


def find_uniq_str(str_list):
    """
    remove redundant structure in str_list
    :param str_list: list of structure metadata generated by parse_str function
    :return: uniq_str_list
    """
    uniq_str_list = []
    for str_dict in str_list:
        i = 0
        while i < len(uniq_str_list):
            if str_dict['LatPnt'] == uniq_str_list[i]['LatPnt'] \
                    and str_dict['Spin'] == uniq_str_list[i]['Spin'] \
                    and str_dict['Type'] == uniq_str_list[i]['Type'] \
                    and str_dict['LatVec'] == uniq_str_list[i]['LatVec']:
                if str_dict['Enrg'] < uniq_str_list[i]['Enrg']:
                    uniq_str_list[i] = str_dict
                break
            else:
                i += 1
        if i >= len(uniq_str_list):
            uniq_str_list.append(str_dict)

    return uniq_str_list


def parse_clust(clust_in):
    """
    Read in the cluster rules and return to the list of clusters
    :param clust_in: file containing cluster rules specified by users
    :return: parsed cluster list (clust_list)
    """
    with open(clust_in) as f:
        data_clust = json.load(f)
    clust_list = data_clust['List']  # list of clusters
    return clust_list


def parse_count(count_out):
    """
    read the count_out file to get a list containing all possible cluster (motifs and decorations)
    :param count_out: file name with counting results
    :return: count list for all structures in a specific sequence
    """
    with open(count_out, 'r') as filehandle:
        count_list = json.load(filehandle)
    deco_list = [[] for _ in count_list[0][1]]
    for i in range(len(count_list)):
        for j in range(len(count_list[i][1])):
            key_name = list(count_list[i][1][j][4].keys())
            for deco in key_name:
                if deco not in deco_list[j]:
                    deco_list[j].append(deco)
    for deco in deco_list:
        deco.sort()
    count = [[] for _ in count_list]
    for i in range(len(count_list)):
        for j in range(len(deco_list)):
            key_name = list(count_list[i][1][j][4].keys())
            for deco in deco_list[j]:
                if deco in key_name:
                    count[i].append(count_list[i][1][j][4][deco])
                else:
                    count[i].append(0)
    print('# of input structures:', len(count_list))
    print('# of input clusters with decoration:', len(count[0]), flush=True)

    return count, deco_list


def parse_enrg(str_out):
    """
    get energy list from str_list
    :param str_out: file name with structure metadata
    :return: enrg
    """
    with open(str_out, 'r') as filehandle:
        str_list = json.load(filehandle)
    enrg = []
    for str_dict in str_list:
        enrg.append(str_dict['Enrg'])

    return enrg


def parse_scaled_enrg(str_out, ep_comp, ep_enrg):
    """
    get rescaled energy list
    :param str_out: file name with structure metadata
    :param ep_comp: endpoint composition in a list like [[1, 0, 0], [0, 1, 0], [0, 0, 1]]
    :param ep_enrg: endpoint energy in a list like [-1, -2, -3]
    :return:
    """
    with open(str_out, 'r') as filehandle:
        str_list = json.load(filehandle)
    enrg = []
    for str_dict in str_list:
        raw_enrg = str_dict['Enrg']
        raw_comp = np.divide(str_dict['AtomNum'], str_dict['AtomSum'])
        trans_matr = np.vstack(ep_comp).T
        inv_matr = np.linalg.inv(trans_matr)
        scale_comp = np.matmul(inv_matr, raw_comp.T)
        scale_enrg = np.subtract(raw_enrg, np.matmul(scale_comp, ep_enrg))
        enrg.append(float(scale_enrg))

    return enrg
